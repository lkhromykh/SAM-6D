import cv2
from ultralytics import YOLO
import torch
from segment_anything import sam_model_registry, SamPredictor
from PIL import Image, ImageDraw
import numpy as np
import time
import argparse


# Fixed colors for 10 classes
class_colors = {
    0: (255, 0, 0),  # Red
    1: (0, 255, 0),  # Green
    2: (0, 0, 255),  # Blue
    3: (255, 255, 0),  # Cyan
    4: (255, 0, 255),  # Magenta
    5: (0, 255, 255),  # Yellow
    6: (128, 0, 128),  # Purple
    7: (0, 128, 255),  # Orange
    8: (128, 128, 0),  # Olive
    9: (0, 0, 128)   # Navy
}

def detect_objects(image_path, yolo_model, object_class, confidence_threshold=0.5):
    import os
    
    start_time = time.time()
    # Load the YOLO model
    model = YOLO(yolo_model)
    end_time = time.time()
    print(f"\nTime to load YOLO model and image: {round(end_time - start_time, 2)} seconds")

    # Load the image
    img = cv2.imread(image_path)
    img_all_detections = img.copy()  # Make a copy for saving all detections

    start_time = time.time()
    # Run inference
    results = model(img, conf=confidence_threshold)
    end_time = time.time()
    print(f"\nTime to detect objects: {round(end_time - start_time, 2)} seconds")

    highest_confidence = 0
    bounding_box_highest_conf = []

    for result in results:
        boxes = result.boxes
        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            conf = box.conf[0].item()
            cls = int(box.cls[0].item())

            # Draw all detections on a separate image
            color_all = class_colors.get(cls, (200, 200, 200))
            cv2.rectangle(img_all_detections, (int(x1), int(y1)), (int(x2), int(y2)), color_all, 2)
            label_all = f"{conf:.2f}, class {cls}"
            cv2.putText(img_all_detections, label_all, (int(x1), int(y1) - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color_all, 2)

            # Only consider detections of the specified class for highest-confidence selection
            if cls != object_class:
                continue

            if conf > highest_confidence:
                highest_confidence = conf
                bounding_box_highest_conf = [round(x1), round(y1), round(x2), round(y2)]

            # Draw this detection on the main image as well
            color = class_colors.get(cls, (255, 255, 255))
            cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
            label = f"{conf:.2f}, class {cls}"
            cv2.putText(img, label, (int(x1), int(y1) - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

    if bounding_box_highest_conf:
        print(f"Bounding box with highest confidence for class {object_class}: {bounding_box_highest_conf}")
        np.save('./YOLO/detection.npy', np.array(bounding_box_highest_conf, dtype=np.int32))
    else:
        print(f"No detections found for class {object_class}")

    # Save images
    os.makedirs('./YOLO', exist_ok=True)
    cv2.imwrite('./YOLO/detections.png', img)             # Detections of selected class
    cv2.imwrite('./YOLO/detections_all.png', img_all_detections)  # All detections

    return bounding_box_highest_conf



def get_mask_using_sam(rgb_path, bounding_box, checkpoint_path="./SAM/checkpoints/segment-anything/sam_vit_h_4b8939.pth"):
    """
    Function to get a mask using SAM model from a given image and bounding box.
    
    Parameters:
        rgb_path (str): Path to the input RGB image.
        bounding_box (list): Bounding box in the format [x1, y1, x2, y2].
        checkpoint_path (str): Path to the SAM model checkpoint. Default is 'sam_vit_h_4b8939.pth'.
        
    Returns:
        np.ndarray: The mask generated by the SAM model.
    """
    
    # Define the bounding box
    # bounding_box = [404., 320., 584., 512.]
    
    # Load the image
    rgb = Image.open(rgb_path).convert("RGB")
    image = np.array(rgb)

    # Load the SAM model
    start_time = time.time()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    sam = sam_model_registry["default"](checkpoint=checkpoint_path)
    sam.to(device)
    end_time = time.time()
    execution_time = end_time - start_time
    print(f"\nTime to load sam model: {round(execution_time, 2)} seconds")

    start_time = time.time()
    # Initialize the predictor
    predictor = SamPredictor(sam)
    predictor.set_image(image)
    # Calculate the execution time
    end_time = time.time()
    execution_time = end_time - start_time
    print(f"\nTime to segment object: {round(execution_time, 2)} seconds\n")

    # Generate the mask
    masks, _, _ = predictor.predict(
        point_coords=None,
        point_labels=None,
        box=np.array([bounding_box]),
        multimask_output=False,
    )

    # Convert the boolean mask to a float32 array (0.0 and 1.0)
    mask_int = masks.astype(np.float32)
    mask_int = mask_int[0]  # Take the first mask

    # Stack the masks along a new axis to create a 3-channel mask
    masks_3 = np.stack([mask_int, mask_int, mask_int], axis=0)

    # Save the mask to a .npy file
    np.save('./SAM/masks.npy', masks_3)

    # Load the mask from the .npy file
    # masks_numpy = np.load('./SAM/masks.npy')

    # Optionally, save the mask as a PNG file (visual representation)
    mask_image = Image.fromarray(masks[0].astype(np.uint8) * 255)
    mask_image.save('./SAM/mask.png')

    # Draw a red bounding box around the mask
    draw = ImageDraw.Draw(mask_image)
    draw.rectangle(bounding_box, outline="red", width=4)

    # Save the image with the bounding box
    mask_image.save("./SAM/mask_with_bbox.png")

    # Return the numpy array of the mask
    return masks_3

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--object_class', type=int, default=0)
    args = parser.parse_args()
    
    image_path = './Data/Inference/rgb.png'  # Path to your image
    yolo_model = './YOLO/checkpoints/best_yolo11m_90_percent_data_for_train.pt'
    object_class = args.object_class
    
    # Object detection with highest confidence
    confidence_threshold = 0.5  # Confidence threshold
    bounding_box_highest_conf = detect_objects(image_path, yolo_model, object_class, confidence_threshold)
    
    # Object segmentation
    masks_numpy = get_mask_using_sam(image_path, bounding_box_highest_conf)
    #print(masks_numpy)
    
    # Template generation